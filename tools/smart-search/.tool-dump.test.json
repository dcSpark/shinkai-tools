{"type":"Deno","content":[{"name":"Smart Search Engine","homepage":null,"author":"@@official.shinkai","version":"1.0.0","mcp_enabled":null,"js_code":"import {\n  googleSearch,\n  duckduckgoSearch,\n  shinkaiLlmPromptProcessor,\n  shinkaiLlmMapReduceProcessor,\n  downloadPages,\n} from './shinkai-local-tools.ts';\n\ntype CONFIG = {\n  searchEngineApiKey?: string;\n  searchEngine?: SearchEngine;\n  maxSources?: number;\n}\ntype INPUTS = {\n  question: string;\n};\ntype OUTPUT =  {\n  response: string;\n  sources: SmartSearchSourcePage[];\n  statements: SmartSearchStatement[];\n}\ntype PREFFERED_SOURCES = 'WIKIPEDIA'|'WEB_SEARCH';\n\ntype SearchQueryConversion = {\n  \"origin_question\": string;\n  \"preferred_sources\": PREFFERED_SOURCES[];\n  \"search_query\": string\n}\n\ntype SearchResult = {\n  title: string;\n  description: string;\n  url: string;\n}\n\ntype SmartSearchSource = SearchResult | string;\nexport type SearchEngine = 'DUCKDUCKGO' | 'GOOGLE' | 'BRAVE';\n\nexport interface SmartSearchSourcePage {\n  id: number;\n  url: string;\n  markdown?: string;\n  title: string;\n}\n\nexport interface SmartSearchStatement {\n  sourceId: number;\n  sourceTitle: string;\n  extractedFacts: {\n    statement: string;\n    relevance: 'DIRECT_ANSWER' | 'HIGHLY_RELEVANT' | 'SOMEWHAT_RELEVANT' | 'TANGENTIAL' | 'NOT_RELEVANT';\n  }[];\n}\nexport interface SmartSearchGenerationContext {\n  originalQuestion: string;\n  statements: SmartSearchStatement[];\n  sources: SmartSearchSourcePage[];\n}\n\nconst answerGenerator = (context: SmartSearchGenerationContext): string => `\n# Smart Search Answer Generation Instructions\nYou are a sophisticated scientific communication assistant specialized in transforming extracted research statements into comprehensive, accessible, and precisely cited explanations.Your primary objective is to synthesize complex information from multiple sources into a clear, authoritative answer that maintains absolute fidelity to the source material. Think of yourself as an academic translator - your role is to take fragmented scientific statements and weave them into a coherent narrative that is both intellectually rigorous and engaging, ensuring that every substantive claim is meticulously attributed to its original source. Approach each question as an opportunity to provide a deep, nuanced understanding that goes beyond surface-level explanation, while maintaining strict scholarly integrity.\n## Input JSON Interfaces and Definitions\n\n\\`\\`\\`typescript\n// Source Page Interface\nexport interface SmartSearchSourcePage {\n  id: number;           // Unique identifier for the source\n  url: string;          // Full URL of the source\n  markdown: string;     // Full text content of the source page\n  title: string;        // Title of the source page\n}\n\n// Statement Interface with Detailed Relevance Levels\nexport interface SmartSearchStatement {\n  sourceId: number;     // ID of the source this statement comes from\n  sourceTitle: string;  // Title of the source\n  extractedFacts: {\n    statement: string;  // Exact verbatim text from the source\n    relevance: 'DIRECT_ANSWER' \n             | 'HIGHLY_RELEVANT' \n             | 'SOMEWHAT_RELEVANT' \n             | 'TANGENTIAL' \n             | 'NOT_RELEVANT';  // Relevance classification\n  }[];\n}\n\n// Complete Input JSON Structure\ninterface AnswerGenerationContext {\n  originalQuestion: string;\n  statements: SmartSearchStatement[];\n  sources: SmartSearchSourcePage[];\n}\n\\`\\`\\`\n\n## Relevance Level Interpretation\n- \\`DIRECT_ANSWER\\`: Prioritize these statements first\n- \\`HIGHLY_RELEVANT\\`: Strong secondary focus\n- \\`SOMEWHAT_RELEVANT\\`: Use for additional context\n- \\`TANGENTIAL\\`: Optional supplementary information\n- \\`NOT_RELEVANT\\`: Ignore completely\n\n## Answer Generation Guidelines\n\n### Content Construction Rules:\n1. Use ONLY information from the provided statements\n2. Prioritize statements with 'DIRECT_ANSWER' and 'HIGHLY_RELEVANT' relevance\n3. Create a comprehensive, informative answer\n4. Maintain scientific accuracy and depth\n\n### Citation Methodology:\n- Place citations IMMEDIATELY after relevant statements\n- Use SQUARE BRACKETS with NUMERIC source IDs\n- Format: \\`Statement of fact.[1][2]\\`\n- Cite EVERY substantive statement\n- Match citations exactly to source IDs\n\n### Structural Requirements:\n1. Detailed Main Answer\n   - Comprehensive explanation\n   - Technical depth\n   - Precise scientific language\n   - Full source citations\n\n2. Follow-Up Questions Section\n   - Generate 3-4 thought-provoking questions\n   - Encourage deeper exploration\n   - Based on answer content\n   - Formatted as a bulleted list\n\n3. Sources Section\n   - List all cited sources\n   - Include source titles and URLs\n   - Order based on first citation appearance\n\n## Output Example Structure:\n\\`\\`\\`\n[Comprehensive, cited answer with source IDs in brackets]\n\nFollow-up Questions:\n- Question about deeper aspect of the topic\n- Question exploring related concepts\n- Question encouraging further research\n\nSources:\n[1] Source Title (URL)\n[2] Another Source Title (URL)\n...\n\\`\\`\\`\n\n## Critical Constraints:\n- NEVER introduce information not in the statements\n- Preserve exact factual content\n- Ensure grammatical and logical coherence\n- Provide a complete, informative answer\n- Maintain academic rigor\n\n## Processing Instructions:\n- Analyze statements systematically\n- Synthesize information coherently\n- Break down complex concepts\n- Provide scientific context\n- Explain underlying mechanisms\n\n\nThis is the input context:\n${JSON.stringify(context)}\n\n`;\n\nconst searchEngineQueryGenerator = (query: string) => {\n  return `\n# Search Query and Source Selection Prompt\n\nYou are an expert at transforming natural language questions into precise search queries and selecting the most appropriate information source.\n\n## Source Selection Guidelines:\n- WEB_SEARCH: General web search for current events, recent developments, practical information\n- WIKIPEDIA: Best for general knowledge, scientific explanations, historical information\n\n## Output Requirements:\n- Provide a JSON response with three key fields\n- Do NOT use code block backticks\n- Ensure \"preferred_sources\" is an array\n- Make search query concise and targeted\n\n## Examples:\n\n### Example 1\n- User Query: \"Who was Marie Curie?\"\n- Output:\n{\n\"origin_question\": \"Who was Marie Curie?\",\n\"preferred_sources\": [\"WIKIPEDIA\"],\n\"search_query\": \"Marie Curie biography scientific achievements\"\n}\n\n### Example 2\n- User Query: \"Best restaurants in New York City\"\n- Output:\n{\n\"origin_question\": \"Best restaurants in New York City\",\n\"preferred_sources\": [\"WEB_SEARCH\"],\n\"search_query\": \"top rated restaurants NYC 2024 dining\"\n}\n\n### Example 3\n- User Query: \"How do solar panels work?\"\n- Output:\n{\n\"origin_question\": \"How do solar panels work?\",\n\"preferred_sources\": [\"WIKIPEDIA\", \"WEB_SEARCH\"],\n\"search_query\": \"solar panel photovoltaic technology mechanism\"\n}\n\n## Instructions:\n- Carefully analyze the user's query\n- Select the MOST APPROPRIATE source(s)\n- Create a targeted search query\n- Return ONLY the JSON without additional text\n- Regarding things like new technologies like blockchain or artifical intelligence or recent scientific discoveries you should always use WEB_SEARCH\n- Regarding things like historical events or consolidated scientific knowledge you should always use WIKIPEDIA\n\nUser Query: ${query}\n`\n\n}\n\nconst statementExtract = (originalQuestion: string, source: SmartSearchSourcePage): string => `\nYou're an expert at extracting facts from a source page. It has been commended to you to extract facts from the source page that are helpful to answer the original question.\nOriginal Question: ${originalQuestion}\nYou will be given a source with the following fields:\n- id: number - Unique identifier for the source\n- url: string - URL of the source page\n- title: string - Title of the source page\n- markdown: string - Full text content of the source page\n\n${JSON.stringify(source)}\n\n# Fact Extraction Instructions\n\nYou will be given the contents of the provided source page. Your job is to extract the facts that are helpful to answer the original question.\nPlease format the facts that will be extracted in an array of objects with the following JSON structure.\n## Output JSON Structure\n\\`\\`\\`json\n{\n  \"sourceId\": \"number - ID of the source\",\n  \"sourceTitle\": \"string - Title of the source\",\n  \"extractedFacts\": [\n    {\n      \"statement\": \"string - Verbatim text from the source\",\n      \"relevance\": \"string - One of ['DIRECT_ANSWER', 'HIGHLY_RELEVANT', 'SOMEWHAT_RELEVANT', 'TANGENTIAL', 'NOT_RELEVANT']\"\n    }\n  ]\n}\n\\`\\`\\`\n\n## Relevance Classification Guide:\n- \\`DIRECT_ANSWER\\`: \n  - Completely and precisely addresses the original question\n  - Contains the core information needed to fully respond\n  - Minimal to no additional context required\n\n- \\`HIGHLY_RELEVANT\\`: \n  - Provides substantial information directly related to the question\n  - Offers critical context or partial solution\n  - Significantly contributes to understanding\n\n- \\`SOMEWHAT_RELEVANT\\`: \n  - Provides partial or indirect information\n  - Offers peripheral insights\n  - Requires additional context to be fully meaningful\n\n- \\`TANGENTIAL\\`: \n  - Loosely connected to the topic\n  - Provides background or related information\n  - Not directly addressing the core question\n\n- \\`NOT_RELEVANT\\`: \n  - No meaningful connection to the original question\n  - Completely unrelated information\n\n\n## Extraction Guidelines:\n1. Read the entire source document carefully\n2. Extract EXACT quotes that:\n  - Are actually helpful answering the provided question\n  - Are stated verbatim from the source or are rephrased in such a way that doesn't distort the meaning in the original source\n  - Represent complete thoughts or meaningful segments\n3. Classify each extracted fact with its relevance level\n4. Preserve original context and nuance\n\n## Critical Rules:\n- try NOT to paraphrase or modify the original text. If you can't find a direct quote or you think the found quote is too long, you can paraphrase it.\n- Avoid any text in the \"statement\" field that is not helpful answering the provided question like javascript, URLs, HTML, and other non-textual content\n- Extract statements as they appear in the source and ONLY if they are helpful answering the provided question\n- Include full sentences or meaningful text segments\n- Preserve original formatting and punctuation\n- Sort extracted facts by relevance (DIRECT_ANSWER first)\n- Output JSON without \\`\\`\\`json\\`\\`\\` tags, or without any escape characters or any text that is not JSON or my system will crash.\n\n## Processing Instructions:\n- Analyze the entire document systematically\n- Be comprehensive in fact extraction\n- Err on the side of inclusion when in doubt\n- Focus on factual, informative statements\n`\nconst debug = []\nconst randomTimeout = () => {\n  const random = (1000 + Math.random() * 2000)|0;\n  console.log(`Waiting for ${random}ms`)\n  return new Promise(resolve => setTimeout(resolve, random));\n}\n\nfunction tryToExtractJSON(text: string): string {\n  const regex = /```(?:json)?\\n([\\s\\S]+?)\\n```/;\n  const match = text.match(regex);\n  if (match) return match[1];\n  else return text;\n}\n\nconst ProcessQuestionError = (step: string, error: Error): string =>\n  `Failed to process question at ${step}: ${error.message}`;\n\nasync function conversionToSearchQuery(question: string): Promise<SearchQueryConversion> {\n  const prompt = searchEngineQueryGenerator(question);\n  const optimizedQueryResult = await shinkaiLlmPromptProcessor({ format: 'text' , prompt });\n  try {\n    const result = JSON.parse(optimizedQueryResult.message.trim()) as SearchQueryConversion;\n    return result;\n  } catch (error) {\n    console.error(error)\n    if (typeof error === 'object') {\n      console.log(JSON.stringify(error, null, 2))\n    }\n    throw new Error(ProcessQuestionError('question processing in optimizequery', new Error(String(error))));\n  }\n}\n\n\nasync function extractSourcesFromSearchEngine(\n  searchQuery: string,\n  engine: SearchEngine,\n  apiKey?: string,\n): Promise<SearchResult[]> {\n  switch (engine) {\n\t\tcase 'GOOGLE' : {\n\t\t\tconst results = await googleSearch({ query: searchQuery });\n\t\t\treturn results.results;\n\t\t}\n    case 'DUCKDUCKGO': {\n      const results = await duckduckgoSearch({ message: searchQuery });\n      if (results.message) return JSON.parse(results.message);\n      return [];\n    }\n    case 'BRAVE': \n      throw new Error('Brave is not supported yet');\n    default:\n      throw new Error('Invalid or unsupperted search engine');\n  }\n}\n\nexport async function run(\n  config: CONFIG,\n  inputs: INPUTS\n): Promise<OUTPUT> {\n  const { question } = inputs;\n  if (!question) {\n    throw new Error('Question is required in inputs');\n  }\n\n  try {\n    // Step 1: Generate optimized search query\n    const searchQuery = await conversionToSearchQuery(question);\n    // Step 2: Perform search with optimized query\n    const sources: SmartSearchSource[] = []\n    for (const preferred_source of searchQuery.preferred_sources) {\n      switch (preferred_source) {\n        case 'WIKIPEDIA':{\n          const searchEngineQuery = searchQuery.search_query+' site:wikipedia.org';\n          const searchEngine = config.searchEngine || 'GOOGLE';\n          const sourcesSearchResults: SearchResult[] = await extractSourcesFromSearchEngine(searchEngineQuery, searchEngine, config.searchEngineApiKey);\n          try {\n            sources.push(...(sourcesSearchResults as SearchResult[]));\n          } catch (error) {\n            console.error('Failed to process search results', error);\n            throw new Error('Failed to process search results');\n          }\n          break;\n        }\n        case 'WEB_SEARCH': {\n          const searchEngineQuery = searchQuery.search_query.trim();\n          const searchEngine = config.searchEngine || 'GOOGLE';\n          const sourcesSearchResults: SearchResult[] = await extractSourcesFromSearchEngine(searchEngineQuery, searchEngine, config.searchEngineApiKey);\n          sources.push(...(sourcesSearchResults as SearchResult[]));\n          break;\n        }\n        default:\n          throw new Error('Invalid source');\n      }\n    }\n    const smartSearchSouces: SmartSearchSourcePage[] = []\n    let id = 1;\n    while (smartSearchSouces.length < Number(config.maxSources ?? 3)) {\n      const source = sources.shift();\n      if (!source) break;\n      if (typeof source === 'string') throw new Error('Invalid source');\n      console.log('+++++++++');\n      console.log(`${id} Downloading source ${source.url}`)\n      console.log('+++++++++');\n      try {\n        const searchResult = await downloadPages({ url: source.url });\n        smartSearchSouces.push({\n          id: id, url: source.url, title: source.title,\n          markdown: searchResult.markdown ?? '',\n        });\n      } catch (error) {\n        console.error('Failed to process source', source.url, error);\n      }\n      id++;\n      await randomTimeout();\n    }\n    console.log('Finished downloading sources');\n    const statements: SmartSearchStatement[] = []\n    // Step 3: Extract statements from sources\n    for (const smartSearchSource of smartSearchSouces) {\n      // TODO use map reduce to extract statements\n      const source = smartSearchSource.markdown;\n      const sourceData = {\n        title: smartSearchSource.title,\n        url: smartSearchSource.url,\n        id: smartSearchSource.id,\n      }\n      const statementString = await shinkaiLlmMapReduceProcessor({ prompt: statementExtract(question, sourceData), data: source as string });\n      const cleanStatementString = tryToExtractJSON(statementString.response)\n      try { \n        const statement = JSON.parse(cleanStatementString) as SmartSearchStatement;\n        statements.push(statement);\n      } catch (error) {\n        console.error('Failed to process statement', smartSearchSource.url, error);\n        console.error(cleanStatementString)\n      }\n    }\n    // clean markdown from sources for lighter input\n    smartSearchSouces.forEach(source => delete source.markdown);\n    const generationContext: SmartSearchGenerationContext = {\n      originalQuestion: question,\n      statements,\n      sources: smartSearchSouces,\n    }\n    // Step 4: Generate answer\n    const answerPrompt = answerGenerator(generationContext);\n\t\tconst response = await shinkaiLlmPromptProcessor({ format: 'text', prompt: answerPrompt });\n    return {\n      statements,\n      sources: smartSearchSouces,\n      response: response.message,\n    };\n  } catch (error) {\n    throw new Error(ProcessQuestionError('question processing in answer generation', new Error(String(error))));\n  }\n}\n","tools":["local:::__official_shinkai:::google_search:::1.0.0","local:::__official_shinkai:::duckduckgo_search:::1.0.0","local:::__official_shinkai:::shinkai_llm_prompt_processor:::1.0.0","local:::__official_shinkai:::shinkai_llm_map_reduce_processor:::1.0.0","local:::__official_shinkai:::download_pages:::1.0.0"],"config":[{"BasicConfig":{"key_name":"searchEngine","description":"The search engine to use","required":false,"type":null,"key_value":null}},{"BasicConfig":{"key_name":"searchEngineApiKey","description":"The API key for the search engine","required":false,"type":null,"key_value":null}},{"BasicConfig":{"key_name":"maxSources","description":"The maximum number of sources to return","required":false,"type":null,"key_value":null}}],"description":"This function takes a question as input and returns a comprehensive answer, along with the sources and statements used to generate the answer.","keywords":["search","answer generation","fact extraction","wikipedia","google"],"input_args":{"type":"object","properties":{"question":{"type":"string","description":"The question to answer"}},"required":["question"]},"output_arg":{"json":""},"activated":false,"embedding":[0.4453733,0.011869535,-0.11069681,-0.22087686,-0.14793433,-0.29252905,-0.47542578,0.44219357,-0.12164926,0.3925404,-0.30060288,1.0142004,0.3621284,-0.3125505,0.67736644,0.25023893,0.35592082,-0.23177312,-1.985065,0.016720742,0.51865655,0.13618343,0.3457152,0.11480483,-0.014056526,0.29596797,0.3189496,-0.38944316,-1.2330377,-1.619294,0.8580937,0.6245402,-0.68500733,-0.40646756,-0.5698067,-0.4462589,-0.018256303,-0.29654965,0.065031,0.08787142,0.12305545,-0.29611173,-0.78903276,-0.2310569,-0.30529577,0.00012451783,-0.10081982,-0.17274743,0.657106,0.5998953,-0.34299478,-0.33238176,-0.27506357,0.054679923,-0.6812951,-0.16974285,-0.3490005,-0.6012764,-0.19499953,-0.30048633,0.61126935,0.13495804,-4.0775933,-0.14073883,0.5235467,0.25485992,0.10941565,-0.37894726,0.3335035,-0.086008444,0.063453004,0.27387738,0.3559412,0.34712785,0.20134854,-0.27503648,-0.16766237,-0.3009599,0.4094591,-0.6049952,-0.33460703,0.03697837,0.16085714,0.18142581,-0.5037787,0.43228182,0.21548957,-0.3988097,0.19260922,-0.07732683,-0.5903561,-0.32283527,-0.33488718,0.086720444,-0.38168892,0.20441626,0.16928822,0.489764,0.4501658,3.2422194,0.30734995,-0.33223715,0.3617341,-1.0973608,0.92212677,-0.32717964,0.15202995,-0.7435656,0.78513587,-0.076416224,0.42161366,-0.20293106,-0.008435324,0.8415193,-0.14816712,0.10041842,-0.48140532,0.09126246,0.08241937,0.73949003,-0.1310586,0.17079106,-0.4367651,-0.33125186,-0.2567683,0.65783924,-0.30973315,0.3683304,0.40847608,0.52424425,0.45959097,-0.55766785,-1.1561068,-0.028591255,0.3414325,0.35104284,0.30437928,-0.84198856,0.63417464,-0.7242719,0.30570382,-1.3069954,0.56030935,-0.11213127,0.74909884,-0.037941054,-0.66385937,-0.22437996,-0.40014225,-0.46955302,0.123438,0.4248774,-0.008499189,-0.03662885,0.7911119,0.4871954,-0.10451915,-0.00076054037,-0.19700727,0.18794638,-0.34423438,0.43148097,0.35341263,0.45135462,0.31922972,-0.38836044,0.14915231,0.46800044,-0.19548723,-0.16418357,0.43799335,-0.46572873,-0.2830555,0.81340206,-0.05229903,-0.29026312,0.14012246,-0.12661734,0.41847602,-0.8826306,-0.1381793,0.7721082,-0.5711713,-0.2707214,-0.19139148,0.45276418,0.08280529,-0.36738992,0.64415497,1.1115812,-0.4716983,1.4448192,-0.23927337,-0.19590464,0.14275151,-0.2150143,0.104985535,0.2708577,0.38772154,0.12917459,-1.0809637,-0.084779724,-0.03931182,-0.30981562,-0.29530922,-0.6517133,0.19348738,-0.32778054,-0.081520334,-0.6484245,0.124725446,-0.5193323,1.1085458,-0.010168031,0.60014606,-0.14031255,0.058668394,0.43037763,-0.4703919,0.81627035,0.21751907,-0.013806134,-0.69446254,-0.6250127,-0.8246181,-0.11285795,0.14311686,0.1276672,-0.27228525,0.008218072,0.58517975,0.92081195,0.46452755,1.3906325,0.76699144,0.52317864,-0.12888616,0.25146693,0.17025617,-0.30913588,0.3188159,-0.110443205,-0.3391856,-0.32499474,0.36716136,-0.5429089,-0.010867845,-0.16743234,0.0649712,1.4561265,0.75501776,0.18447715,-0.045385074,0.9046099,-0.14438653,0.16843936,-1.6038208,0.07896763,-0.30478138,0.4590311,-0.011303078,-0.31313077,0.39998955,0.3538165,-0.6008238,-0.8335624,-0.3721661,-0.80940664,-0.17522807,-0.06533244,-0.10935128,0.35936123,-0.47540838,-0.042938784,0.50271595,0.15231198,0.3528767,0.5737877,-0.58173335,-0.13813534,0.4038029,0.15426363,0.10372652,0.2488796,-0.14705679,-0.19004944,-0.45239034,-0.06804096,-0.45102888,0.7760274,-0.47770083,-0.5009155,-0.63347554,0.32182592,1.610656,0.3123873,-0.27355373,0.85143435,-0.10789341,-0.08307878,0.32733703,0.3440173,-0.102377914,0.14756584,-0.21751344,-0.7646928,0.70526314,-0.4305198,-0.34848696,-0.07646395,-0.89381826,-0.25966865,0.08521283,-0.3562976,0.1788072,-0.43712464,0.8471677,0.42158654,0.47272462,-2.0370617,-0.28899717,0.22787738,0.02287806,0.033739775,-0.8462857,0.6192919,-0.36559322,0.5273773,-0.8520617,1.7013099,0.62358445,-0.34571034,-0.29234827,0.22244722,1.0091611,-0.55843914,-0.10037386,-0.20216328,-0.14148596,0.29943207,0.3575117,1.7770641,0.4495375,0.18052875,0.17174764,0.110289656,-0.1854283,-1.3959241,0.18649822,0.4356429,-0.32748318,0.5604379,-0.083616495,-0.45709422,0.45563444,1.0321977,0.27883914,0.1971579,-0.0058335187,2.0173717,0.1420698,-0.33268648,-0.4823374,-0.44468617,-0.44315258,0.33924997,0.24738382,-0.22844762,0.23638512,-0.42327982,-0.117742166,-0.19422874,0.28134382,-0.063594535,0.28325847,0.49690092,-0.1586755,0.6844982,0.3888109,-0.17269313,0.74644864,0.036682565,-1.085391,-0.24839278],"result":{"type":"object","properties":{"response":{"description":"The generated answer","type":"string"},"sources":{"description":"The sources used to generate the answer","items":{"properties":{"id":{"type":"number"},"title":{"type":"string"},"url":{"type":"string"}},"type":"object"},"type":"array"},"statements":{"description":"The statements extracted from the sources","items":{"properties":{"extractedFacts":{"items":{"properties":{"relevance":{"type":"string"},"statement":{"type":"string"}},"type":"object"},"type":"array"},"sourceId":{"type":"number"},"sourceTitle":{"type":"string"}},"type":"object"},"type":"array"}},"required":["response","sources","statements"]},"sql_tables":[],"sql_queries":[],"file_inbox":null,"oauth":null,"assets":null,"runner":"any","operating_system":["linux","macos","windows"],"tool_set":""},false]}